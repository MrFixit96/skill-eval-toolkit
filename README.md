# Skill Eval Toolkit

A [Copilot CLI](https://githubnext.com/projects/copilot-cli/) plugin for evaluating, diagnosing, and improving AI agent skill files. Codifies the **diagnose â†’ research â†’ fix â†’ validate** improvement cycle as reusable commands, agents, and GitHub Agentic Workflow templates.

**v2.0.0** â€” Now includes [GitHub Agentic Workflows](https://github.github.io/gh-aw/introduction/overview/) for fully autonomous CI/CD skill quality management.

## Installation

### As a Copilot CLI Plugin

```bash
# Clone into your plugins directory
git clone https://github.com/MrFixit96/skill-eval-toolkit.git \
  ~/.copilot/installed-plugins/skill-eval-toolkit

# Or add as a git submodule in an existing plugins repo
git submodule add https://github.com/MrFixit96/skill-eval-toolkit.git \
  plugins/skill-eval-toolkit
```

Copilot CLI auto-discovers plugins from `~/.copilot/installed-plugins/` and `plugins/` directories â€” no further configuration needed.

### Agentic Workflows (CI/CD)

To also install the agentic workflow templates into your repository:

```bash
# Prerequisites
gh extension install github/gh-aw
cd your-skills-repo
gh aw init

# Add workflow templates (pick what you need)
gh aw add MrFixit96/skill-eval-toolkit/workflows/skill-lint           # Phase 1: lint on push/PR
gh aw add MrFixit96/skill-eval-toolkit/workflows/skill-eval           # Phase 1: full 3-tier eval
gh aw add MrFixit96/skill-eval-toolkit/workflows/skill-improver       # Phase 1: autonomous fix cycle
gh aw add MrFixit96/skill-eval-toolkit/workflows/skill-eval-orchestrator  # Phase 2: fleet orchestrator
gh aw add MrFixit96/skill-eval-toolkit/workflows/gepa-evaluator       # Phase 3: GEPA fitness function
gh aw add MrFixit96/skill-eval-toolkit/workflows/gepa-optimizer       # Phase 3: evolutionary search

# Configure required secrets
gh aw secrets bootstrap                                    # COPILOT_GITHUB_TOKEN (required)
gh secret set MODELS_PAT --body "your-github-models-pat"   # Tier 2/3 eval (optional)

# Compile and push
gh aw compile
git add .github && git commit -m "Add skill-eval agentic workflows" && git push
```

## What's Included

### Commands

| Command | Description |
|---------|-------------|
| `/eval-skills` | Run Tier 1 validation locally (lint + score + trigger coverage) |
| `/eval-skills tier2` | Also run semantic trigger evaluation (requires `MODELS_PAT`) |
| `/eval-skills tier3` | Run full A/B effectiveness judge |
| `/improve-skill <name>` | Full improvement cycle on a named skill |

### Agents

| Agent | Description |
|-------|-------------|
| `skill-improver` | Reads eval failures, researches official docs, makes surgical fixes, validates |
| `skill-diagnostician` | Analyzes eval results and produces actionable diagnoses with priorities |

### Skills

| Skill | Description |
|-------|-------------|
| `skill-eval` | Reference knowledge about the 3-tier eval framework, scoring rubric, and improvement methodology |

### Agentic Workflows

| Workflow | Trigger | Description | Phase |
|----------|---------|-------------|-------|
| `skill-lint` | push, PR, manual | Structural lint + content scoring + trigger coverage | 1 |
| `skill-eval` | weekly, manual | Full 3-tier evaluation suite with issue report | 1 |
| `skill-improver` | issue label, manual | Autonomous diagnose â†’ research â†’ fix â†’ validate cycle | 1 |
| `skill-eval-orchestrator` | weekly, manual | Fleet-wide eval, dispatches improvement workers per skill | 2 |
| `gepa-evaluator` | manual | GEPA fitness function â€” evaluates a single skill candidate with ASI | 3 |
| `gepa-optimizer` | manual | GEPA evolutionary search â€” evolves skills through Pareto selection | 3 |

### Shared Components

| Component | Description |
|-----------|-------------|
| `shared/eval-tools.md` | Common tool and runtime configuration (Python 3.12, bash commands) |
| `shared/skill-knowledge.md` | Evaluation framework knowledge (tiers, scoring, methodology) |
| `shared/gepa-config.md` | GEPA default parameters, Pareto criteria, stop conditions |

## Usage

### Local Commands (Interactive)

```bash
# Run Tier 1 evaluation across all skills
/eval-skills

# Improve a specific skill that's below threshold
/improve-skill golang

# Ask the diagnostician to analyze recent eval results
# (invoke skill-diagnostician agent via task tool or by name)
```

### Agentic Workflows (CI/CD)

```bash
# Trigger lint check manually
gh aw run skill-lint

# Trigger full fleet evaluation
gh aw run skill-eval-orchestrator

# Improve a specific skill via workflow dispatch
gh aw run skill-improver -- --skill_name golang --threshold_score 85

# Run GEPA evolutionary optimization on a skill
gh aw run gepa-optimizer -- --skill_name rust --generations 5 --population_size 3

# Check workflow status
gh aw status
```

### Automated Triggers

Once installed and compiled, workflows run automatically:

- **On push/PR** (paths: `skills/**`, `scripts/**`, `tests/**`): `skill-lint` runs Tier 1 checks and comments results
- **Weekly**: `skill-eval-orchestrator` evaluates all skills and dispatches improvement workers for any below threshold
- **On issue label** (`skill-improvement`): `skill-improver` autonomously fixes the named skill and creates a PR

## The Improvement Cycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Diagnose â”‚â”€â”€â”€â†’â”‚ Research  â”‚â”€â”€â”€â†’â”‚   Fix    â”‚â”€â”€â”€â†’â”‚ Validate â”‚
â”‚          â”‚    â”‚          â”‚    â”‚          â”‚    â”‚          â”‚
â”‚ Parse    â”‚    â”‚ Fetch    â”‚    â”‚ Surgical â”‚    â”‚ Lint +   â”‚
â”‚ judge    â”‚    â”‚ official â”‚    â”‚ edits to â”‚    â”‚ score +  â”‚
â”‚ reasoningâ”‚    â”‚ docs for â”‚    â”‚ SKILL.md â”‚    â”‚ trigger  â”‚
â”‚ from evalâ”‚    â”‚ accuracy â”‚    â”‚ only     â”‚    â”‚ coverage â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†‘                                               â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    Re-evaluate if needed
```

## 3-Tier Evaluation System

| Tier | Cost | What It Measures | Scripts |
|------|------|-----------------|---------|
| **1** | Free (no API) | Structure, content depth (0â€“100), trigger keyword coverage | `lint-skills.py`, `score-skills.py`, `trigger-coverage.py` |
| **2** | 7 API calls | Semantic trigger accuracy â€” LLM judges description activation | `eval-trigger-semantic.py` |
| **3** | 75+ API calls | A/B effectiveness â€” LLM compares skill-augmented vs baseline responses | `eval-skill-effectiveness.py` |

**Thresholds**: Skills must pass lint (100%) and score â‰¥85/100. Fleet target: â‰¥95 average, â‰¥80% Tier 3 win rate.

## GEPA Evolutionary Optimization (Phase 3)

GEPA (Genetic-Pareto optimizer) evolves skill files through LLM-guided mutation and multi-objective selection. Instead of scalar rewards, it uses **Actionable Side Information (ASI)** â€” the judge's full reasoning from Tier 3 evaluation â€” to guide mutations.

```
Seed SKILL.md â†’ [Mutate based on ASI] â†’ Evaluate â†’ Pareto Select â†’ Repeat
```

- **Population**: 3 candidates per generation (configurable)
- **Generations**: 5 cycles (configurable)
- **Selection**: Multi-objective Pareto dominance (content score â†‘, trigger coverage â†‘, win rate â†‘, lint failures â†“)
- **Stop early**: When any candidate hits score â‰¥95, lint pass, 100% triggers, â‰¥90% win rate

> âš ï¸ GEPA workflows are expensive. They're gated behind manual `workflow_dispatch` only.

## Prerequisites

- [GitHub Copilot CLI](https://githubnext.com/projects/copilot-cli/) v0.0.415+
- [gh CLI](https://cli.github.com/) v2.50+ (for agentic workflows)
- [gh-aw extension](https://github.com/github/gh-aw) v0.50+ (for agentic workflows)
- Python 3.12+ (for eval scripts)
- Repository secrets:
  - `COPILOT_GITHUB_TOKEN` â€” Fine-grained PAT with `Copilot Requests: Read-only` (required for agentic workflows)
  - `MODELS_PAT` â€” GitHub Models API token (optional, for Tier 2/3 evaluation)

## Repository Structure

```
skill-eval-toolkit/
â”œâ”€â”€ .claude-plugin/
â”‚   â””â”€â”€ plugin.json           # Plugin manifest (v2.0.0)
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ skill-improver.md     # Autonomous improvement agent
â”‚   â””â”€â”€ skill-diagnostician.md # Eval result analysis agent
â”œâ”€â”€ commands/
â”‚   â”œâ”€â”€ eval-skills.md        # /eval-skills command
â”‚   â””â”€â”€ improve-skill.md      # /improve-skill command
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ ai-coding-agent-comparison.md  # Platform comparison matrix
â”œâ”€â”€ skills/
â”‚   â””â”€â”€ skill-eval/
â”‚       â””â”€â”€ SKILL.md          # Eval framework knowledge
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ shared/
â”‚   â”‚   â”œâ”€â”€ eval-tools.md     # Common tool config (import)
â”‚   â”‚   â”œâ”€â”€ skill-knowledge.md # Eval knowledge (import)
â”‚   â”‚   â””â”€â”€ gepa-config.md    # GEPA parameters (import)
â”‚   â”œâ”€â”€ skill-lint.md         # Phase 1: lint on push/PR
â”‚   â”œâ”€â”€ skill-eval.md         # Phase 1: 3-tier eval suite
â”‚   â”œâ”€â”€ skill-improver.md     # Phase 1: autonomous fix cycle
â”‚   â”œâ”€â”€ skill-eval-orchestrator.md # Phase 2: fleet orchestrator
â”‚   â”œâ”€â”€ gepa-evaluator.md     # Phase 3: fitness function
â”‚   â”œâ”€â”€ gepa-optimizer.md     # Phase 3: evolutionary search
â”‚   â””â”€â”€ README.md             # Workflow-specific docs
â”œâ”€â”€ .gitignore
â”œâ”€â”€ CROSS-PLATFORM.md         # Cross-platform implementation guide
â”œâ”€â”€ LICENSE                   # MIT
â””â”€â”€ README.md                 # This file
```

## Security

- Agentic workflows run in **read-only sandboxed containers** with firewall (AWF)
- All writes go through **safe-outputs** (create-pull-request, create-issue, add-comment) â€” never direct pushes
- Skill names are **validated against the `skills/` directory listing** before any file operations to prevent path traversal
- Network access is restricted to an **explicit domain allowlist** per workflow
- Bot-triggered runs are skipped via `skip-bots` to prevent infinite loops

## Cross-Platform Support

This plugin's core primitives (commands, agents, skills) work in **GitHub Copilot CLI**, **Claude Code**, and **OpenCode** natively â€” they share compatible plugin/skill formats. The CI/CD workflows can be adapted for **Gemini CLI** and **Codex CLI** as well.

- ğŸ“˜ **[Cross-Platform Implementation Guide](CROSS-PLATFORM.md)** â€” How to run these workflows on Claude Code, Gemini CLI, Codex CLI, and OpenCode with concrete examples for each platform.
- ğŸ“Š **[AI Coding Agent Comparison Matrix](docs/ai-coding-agent-comparison.md)** â€” Full 26-capability comparison of all five platforms: feature matrix, hook events, plugin primitives, cost models, and architecture diagrams.

## License

MIT â€” see [LICENSE](LICENSE)
